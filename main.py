from PyQt6.QtWidgets import QApplication, QMainWindow, QWidget, QVBoxLayout, QPushButton, QLabel, QComboBox, QGroupBox, QHBoxLayout, QFileDialog, QLineEdit, QMessageBox, QSystemTrayIcon, QMenu, QDialog
from PyQt6.QtCore import Qt, QTimer, QRect, QPoint, QEvent
from PyQt6.QtGui import QImage, QPixmap, QPainter, QPen, QColor
import cv2
import sys
import sounddevice as sd
import numpy as np
from mss import mss
import queue
import threading
import os
from datetime import datetime
import wave
import time
import ffmpeg
import subprocess
import soundcard as sc
from pydub import AudioSegment
import io
import psutil

class SelectAreaDialog(QDialog):
    """æ¡†é€‰åŒºåŸŸå¯¹è¯æ¡†"""
    def __init__(self):
        super().__init__()
        self.setWindowFlags(Qt.WindowType.FramelessWindowHint | Qt.WindowType.WindowStaysOnTopHint)
        self.setWindowState(Qt.WindowState.WindowFullScreen)
        
        # æ•è·æ•´ä¸ªå±å¹•
        screen = QApplication.primaryScreen()
        self.screenshot = screen.grabWindow(0)
        
        # è®¾ç½®åŠé€æ˜èƒŒæ™¯
        self.setStyleSheet("background-color: rgba(0, 0, 0, 50);")
        
        self.begin = QPoint()
        self.end = QPoint()
        self.is_drawing = False
        self.selected_rect = None
    
    def paintEvent(self, event):
        painter = QPainter(self)
        
        # ç»˜åˆ¶å±å¹•æˆªå›¾
        painter.drawPixmap(0, 0, self.screenshot)
        
        # æ·»åŠ åŠé€æ˜é®ç½©
        painter.fillRect(self.rect(), QColor(0, 0, 0, 100))
        
        if self.is_drawing or self.selected_rect:
            # è®¾ç½®é€‰æ‹©æ¡†çš„æ ·å¼
            painter.setPen(QPen(QColor(255, 0, 0), 2))
            
            if self.is_drawing:
                rect = QRect(self.begin, self.end)
            else:
                rect = self.selected_rect
            
            # æ¸…é™¤é€‰æ‹©åŒºåŸŸçš„é®ç½©
            painter.setCompositionMode(QPainter.CompositionMode.CompositionMode_Clear)
            painter.fillRect(rect, Qt.GlobalColor.transparent)
            painter.setCompositionMode(QPainter.CompositionMode.CompositionMode_SourceOver)
            
            # ç»˜åˆ¶é€‰æ‹©æ¡†
            painter.drawRect(rect)
            
            # æ˜¾ç¤ºå°ºå¯¸ä¿¡æ¯
            size_text = f"{rect.width()} x {rect.height()}"
            painter.setPen(QPen(QColor(255, 255, 255)))
            painter.drawText(rect.center(), size_text)
    
    def mousePressEvent(self, event):
        self.begin = event.pos()
        self.end = self.begin
        self.is_drawing = True
        self.selected_rect = None
        self.update()
    
    def mouseMoveEvent(self, event):
        if self.is_drawing:
            self.end = event.pos()
            self.update()
    
    def mouseReleaseEvent(self, event):
        self.is_drawing = False
        self.selected_rect = QRect(self.begin, self.end).normalized()
        self.update()
        # å»¶è¿Ÿå…³é—­ï¼Œè®©ç”¨æˆ·çœ‹åˆ°æœ€ç»ˆçš„é€‰æ‹©åŒºåŸŸ
        QTimer.singleShot(500, self.accept)

class StreamingApp(QMainWindow):
    def __init__(self):
        super().__init__()
        self.setWindowTitle("ç®€æ˜“ç›´æ’­è½¯ä»¶")
        self.setGeometry(100, 100, 1280, 720)  # å¢å¤§çª—å£å°ºå¯¸
        
        # å»ºä¸»çª—å£éƒ¨ä»¶
        main_widget = QWidget()
        self.setCentralWidget(main_widget)
        
        # ä½¿ç”¨æ°´å¹³å¸ƒå±€åˆ†å‰²å·¦å³ä¸¤éƒ¨åˆ†
        main_layout = QHBoxLayout()
        
        # å·¦ä¾§é¢„è§ˆåŒºåŸŸ
        preview_layout = QVBoxLayout()
        
        # é¢„è§ˆçª—å£
        self.preview_label = QLabel()
        self.preview_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.preview_label.setMinimumSize(800, 450)  # 16:9 æ¯”ä¾‹
        self.preview_label.setStyleSheet("QLabel { background-color: black; }")
        preview_layout.addWidget(self.preview_label, stretch=1)  # stretch=1 ä½¿å…¶å æ®æ‰€æœ‰å¯ç”¨ç©ºé—´
        
        # ç›´æ’­æ§åˆ¶æŒ‰é’®
        stream_control_layout = QHBoxLayout()
        self.start_button = QPushButton("å¼€å§‹ç›´æ’­")
        self.start_button.setMinimumHeight(40)
        self.start_button.clicked.connect(self.toggle_streaming)
        stream_control_layout.addWidget(self.start_button)
        preview_layout.addLayout(stream_control_layout)
        
        # å°†å·¦ä¾§å¸ƒå±€æ·»åŠ åˆ°ä¸»å¸ƒå±€
        main_layout.addLayout(preview_layout, stretch=2)  # å·¦ä¾§å æ®2/3ç©ºé—´
        
        # å³ä¾§æ§åˆ¶é¢æ¿
        control_panel = QWidget()
        control_layout = QVBoxLayout()
        control_panel.setMaximumWidth(400)  # é™åˆ¶å³ä¾§æ§åˆ¶é¢æ¿å®½åº¦
        
        # è®¾å¤‡é€‰æ‹©åŒºåŸŸ
        devices_group = QGroupBox("è®¾å¤‡é€‰æ‹©")
        devices_layout = QVBoxLayout()
        
        # æ‘„åƒå¤´é€‰æ‹©åŒºåŸŸ
        camera_layout = QHBoxLayout()
        camera_label = QLabel("è§†é¢‘è®¾å¤‡:")
        self.camera_combo = QComboBox()
        # è·å–å¯ç”¨çš„æ‘„åƒå¤´åˆ—è¡¨
        self.update_camera_list()
        camera_layout.addWidget(camera_label)
        camera_layout.addWidget(self.camera_combo)
        devices_layout.addLayout(camera_layout)
        
        # éŸ³é¢‘è¾“å…¥è®¾ï¿½ï¿½é€‰æ‹©
        audio_in_layout = QHBoxLayout()
        audio_in_label = QLabel("éŸ³é¢‘è¾“å…¥:")
        self.audio_in_combo = QComboBox()
        self.audio_in_combo.addItems(self.get_audio_devices())
        audio_in_layout.addWidget(audio_in_label)
        audio_in_layout.addWidget(self.audio_in_combo)
        devices_layout.addLayout(audio_in_layout)
        
        # åœ¨è®¾å¤‡é€‰æ‹©åŒºåŸŸæ·»åŠ èƒŒæ™¯éŸ³é€‰æ‹©
        bgm_layout = QHBoxLayout()
        bgm_label = QLabel("èƒŒæ™¯éŸ³ä¹:")
        self.bgm_path = None
        self.bgm_label = QLabel("æœªé€‰æ‹©")
        select_bgm_button = QPushButton("é€‰æ‹©éŸ³ä¹")
        select_bgm_button.clicked.connect(self.select_bgm)
        bgm_layout.addWidget(bgm_label)
        bgm_layout.addWidget(self.bgm_label)
        bgm_layout.addWidget(select_bgm_button)
        devices_layout.addLayout(bgm_layout)
        
        # ä¿®æ”¹çª—å£æ•è·é€‰æ‹©
        window_layout = QHBoxLayout()
        window_label = QLabel("æ•è·é€‰æ‹©:")
        self.window_combo = QComboBox()
        self.window_combo.addItems(["å…¨å±", "æ¡†é€‰åŒºåŸŸ"])  # æ·»åŠ æ¡†é€‰åŒºåŸŸé€‰é¡¹
        self.update_window_list()
        window_layout.addWidget(window_label)
        window_layout.addWidget(self.window_combo)
        devices_layout.addLayout(window_layout)
        
        # åˆ·æ–°æŒ‰ï¿½ï¿½ï¿½
        refresh_button = QPushButton("åˆ·æ–°è®¾å¤‡åˆ—è¡¨")
        refresh_button.clicked.connect(self.refresh_devices)
        devices_layout.addWidget(refresh_button)
        
        devices_group.setLayout(devices_layout)
        control_layout.addWidget(devices_group)
        
        # æ¨æµè®¾ç½®åŒºåŸŸ
        stream_group = QGroupBox("æ¨æµè®¾ç½®")
        stream_layout = QVBoxLayout()
        
        # æ¨æµåœ°å€è¾“å…¥
        stream_url_layout = QHBoxLayout()
        stream_url_label = QLabel("æ¨æµåœ°å€:")
        self.stream_url_input = QLineEdit()
        self.stream_url_input.setPlaceholderText("rtmp://your-streaming-server/live/stream-key")
        stream_url_layout.addWidget(stream_url_label)
        stream_url_layout.addWidget(self.stream_url_input)
        stream_layout.addLayout(stream_url_layout)
        
        stream_group.setLayout(stream_layout)
        control_layout.addWidget(stream_group)
        
        # å½•åˆ¶æ§åˆ¶åŒºåŸŸ
        recording_group = QGroupBox("å½•åˆ¶æ§åˆ¶")
        recording_layout = QVBoxLayout()
        
        # ä¿å­˜è·¯å¾„é€‰æ‹©
        save_path_layout = QHBoxLayout()
        self.save_path_label = QLabel("ä¿å­˜è·¯å¾„: æœªé€‰æ‹©")
        self.save_path = "D:/"  # ä¿®æ”¹é»˜è®¤ä¿å­˜è·¯å¾„
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        if not os.path.exists(self.save_path):
            os.makedirs(self.save_path)
        self.save_path_label.setText(f"ä¿å­˜è·¯å¾„: {self.save_path}")
        
        select_path_button = QPushButton("é€‰æ‹©ä¿å­˜è·¯å¾„")
        select_path_button.clicked.connect(self.select_save_path)
        save_path_layout.addWidget(self.save_path_label)
        save_path_layout.addWidget(select_path_button)
        recording_layout.addLayout(save_path_layout)
        
        # å½•åˆ¶æ§åˆ¶æŒ‰é’®
        record_control_layout = QHBoxLayout()
        self.record_button = QPushButton("å¼€å§‹å½•åˆ¶")
        self.record_button.clicked.connect(self.toggle_recording)
        record_control_layout.addWidget(self.record_button)
        recording_layout.addLayout(record_control_layout)
        
        # åœ¨å½•åˆ¶æ§åˆ¶åŒºåŸŸæ·»åŠ å½•åˆ¶æ—¶é•¿æ˜¾ç¤º
        self.recording_time_label = QLabel("å½•åˆ¶æ—¶é•¿: 00:00:00")
        recording_layout.addWidget(self.recording_time_label)
        
        # æ·»åŠ å½•åˆ¶çŠ¶æ€æŒ‡ç¤º
        status_layout = QHBoxLayout()
        self.recording_status_label = QLabel("æœªå½•åˆ¶")
        status_layout.addWidget(self.recording_status_label)
        recording_layout.addLayout(status_layout)
        
        recording_group.setLayout(recording_layout)
        control_layout.addWidget(recording_group)
        
        # ï¿½ï¿½åŠ æ‰€æœ‰ç»„åˆ°å³ä¾§æ§åˆ¶é¢æ¿
        control_layout.addStretch()  # æ·»åŠ å¼¹æ€§ç©ºé—´
        
        control_panel.setLayout(control_layout)
        main_layout.addWidget(control_panel)  # å³ä¾§å æ®1/3ç©ºé—´
        
        main_widget.setLayout(main_layout)
        
        # è§†é¢‘æ•è·
        self.capture = None
        self.streaming = False
        
        # æ—¶å™¨ç”¨äºæ›´æ–°é¢„è§ˆ
        self.timer = QTimer()
        self.timer.timeout.connect(self.update_preview)
        
        # åœ¨ç±»åˆå§‹åŒ–ä¸­æ·»åŠ æ–°çš„æˆå‘˜å˜é‡
        self.screen_capture = mss()
        self.audio_queue = queue.Queue()
        self.audio_thread = None
        self.recording_audio = False
        
        # æ·»åŠ å½•åˆ¶ç›¸å…³çš„æˆå‘˜å˜é‡
        self.recording = False
        self.video_writer = None
        self.recording_start_time = None
        
        # æ·»åŠ å½•åˆ¶æ—¶é•¿æ›´æ–°å®šæ—¶å™¨
        self.recording_timer = QTimer()
        self.recording_timer.timeout.connect(self.update_recording_time)
        
        # æ·»åŠ éŸ³é¢‘å½•åˆ¶ç›¸å…³å˜é‡
        self.audio_file = None
        self.audio_writer = None
        self.is_recording_audio = False
        
        # æ·»åŠ æ¨æµç›¸å…³å˜é‡
        self.ffmpeg_process = None
        self.stream_pipe = None
        
        # æ·»åŠ ç³»ç»Ÿæ‰˜ç›˜å›¾æ ‡æ”¯ï¿½ï¿½ï¿½
        self.tray_icon = None
        
        # æ·»åŠ æ€§èƒ½ç›‘æ§
        self.performance_timer = QTimer()
        self.performance_timer.timeout.connect(self.monitor_performance)
        self.performance_timer.start(5000)  # æ¯5ç§’ç›‘æ§ä¸€æ¬¡
        self.frame_count = 0
        self.last_frame_time = time.time()
        
    def toggle_streaming(self):
        if not self.streaming:
            self.start_streaming()
        else:
            self.stop_streaming()
    
    def start_streaming(self):
        """å¼€å§‹ç›´æ’­"""
        try:
            # ä½¿ç”¨é»˜è®¤åœ°å€ï¼Œä¸å†æ£€æŸ¥æ˜¯å¦ä¸ºç©º
            stream_url = self.stream_url_input.text().strip() or "udp://127.0.0.1:1234"
            self.stream_url_input.setText(stream_url)  # æ˜¾ç¤ºä½¿ç”¨çš„åœ°å€
            
            selected_mode = self.window_combo.currentText()
            
            # å…¨å±æ¨¡å¼
            if selected_mode == "å…¨å±":
                screen = QApplication.primaryScreen()
                size = screen.size()
                self.capture_region = {
                    'left': 0,
                    'top': 0,
                    'width': size.width(),
                    'height': size.height()
                }
                self.streaming = True
                self.start_button.setText("åœæ­¢ç›´æ’­")
                self.timer.start(16)  # çº¦60fpsçš„æ›´æ–°é¢‘ç‡ï¼Œè®©ç³»ç»Ÿè‡ªå·±è°ƒèŠ‚åˆ°30fps
                self.start_ffmpeg_stream()
                return
            
            # æ¡†é€‰åŒºåŸŸæ¨¡å¼
            elif selected_mode == "æ¡†é€‰åŒºåŸŸ":
                if self.select_area():
                    self.streaming = True
                    self.start_button.setText("åœæ­¢ç›´æ’­")
                    self.timer.start(16)  # çº¦60fpsçš„æ›´æ–°é¢‘ç‡ï¼Œè®©ç³»ç»Ÿè‡ªå·±è°ƒèŠ‚åˆ°30fps
                    self.start_ffmpeg_stream()
                return
            
            # çª—å£æ•è·æ¨¡å¼
            elif selected_mode not in ["æ— å¯ç”¨æ‘„åƒå¤´", "éœ€è¦å®‰è£…pywin32åº“"]:
                try:
                    import win32gui
                    hwnd = win32gui.FindWindow(None, selected_mode)
                    if hwnd:
                        rect = win32gui.GetWindowRect(hwnd)
                        self.capture_region = {
                            'left': rect[0],
                            'top': rect[1],
                            'width': rect[2] - rect[0],
                            'height': rect[3] - rect[1]
                        }
                        self.target_window = hwnd
                        self.streaming = True
                        self.start_button.setText("åœæ­¢ç›´æ’­")
                        self.timer.start(16)  # çº¦60fpsçš„æ›´æ–°é¢‘ç‡ï¼Œè®©ç³»ç»Ÿè‡ªå·±è°ƒèŠ‚åˆ°30fps
                        self.start_ffmpeg_stream()
                        return
                except ImportError:
                    print("æœªå®‰è£…pywin32åº“ï¼Œæ— æ³•æ•è·çª—å£")
                except Exception as e:
                    print(f"çª—å£æ•è·å‡ºé”™: {str(e)}")
            
            # æ‘„åƒå¤´æ¨¡å¼
            camera_text = self.camera_combo.currentText()
            if camera_text != "æ— å¯ç”¨æ‘„åƒå¤´":
                try:
                    camera_index = int(camera_text.split(" ")[1])
                    self.capture = cv2.VideoCapture(camera_index)
                    if self.capture.isOpened():
                        self.streaming = True
                        self.start_button.setText("åœæ­¢ç›´æ’­")
                        self.timer.start(16)  # çº¦60fpsçš„æ›´æ–°é¢‘ç‡ï¼Œè®©ç³»ç»Ÿè‡ªå·±è°ƒèŠ‚åˆ°30fps
                        self.start_ffmpeg_stream()
                    else:
                        print("æ— æ³•æ‰“å¼€æ‘„åƒå¤´")
                        self.capture = None
                except Exception as e:
                    print(f"æ‰“å¼€æ‘„åƒå¤´å‡ºé”™: {str(e)}")
                    if self.capture:
                        self.capture.release()
                        self.capture = None
            else:
                print("æ²¡æœ‰å¯ç”¨çš„æ‘„åƒå¤´ï¼Œè¯·é€‰æ‹©å…¶ä»–æ•è·æ¨¡å¼")
            
        except Exception as e:
            print(f"å¼€å§‹ç›´æ’­æ—¶å‡ºé”™: {str(e)}")
            self.stop_streaming()
    
    def start_ffmpeg_stream(self):
        """å¯åŠ¨FFmpegæ¨æµè¿›ç¨‹"""
        try:
            if hasattr(self, 'ffmpeg_process') and self.ffmpeg_process:
                self.ffmpeg_process.terminate()
                self.ffmpeg_process.wait()
                self.ffmpeg_process = None

            # è·å–æ¨æµåœ°å€
            stream_url = self.stream_url_input.text().strip()
            if not stream_url:
                print("è¯·è¾“å…¥å®Œæ•´çš„æ¨æµåœ°å€ï¼ŒåŒ…æ‹¬æ¨æµå¯†é’¥")
                return
            
            # è·å–è§†é¢‘å°ºå¯¸å¹¶è°ƒæ•´ä¸º2çš„å€æ•°
            if hasattr(self, 'capture_region'):
                width = self.capture_region['width']
                height = self.capture_region['height']
            elif self.capture and self.capture.isOpened():
                width = int(self.capture.get(cv2.CAP_PROP_FRAME_WIDTH))
                height = int(self.capture.get(cv2.CAP_PROP_FRAME_HEIGHT))
            else:
                raise Exception("æ— æ³•è·å–è§†é¢‘å°ºå¯¸")
            
            # ç¡®ä¿å®½é«˜éƒ½æ˜¯2çš„å€æ•°
            width = width - (width % 2)
            height = height - (height % 2)
            
            command = [
                'ffmpeg',
                '-y',  # è¦†ç›–è¾“å‡ºæ–‡ä»¶
                '-f', 'rawvideo',
                '-vcodec', 'rawvideo',
                '-pix_fmt', 'bgr24',
                '-s', f'{width}x{height}',
                '-r', '30',
                '-i', '-',  # ä»ç®¡é“è¯»å–è§†é¢‘
            ]
            
            # å¦‚æœæœ‰èƒŒæ™¯éŸ³ä¹ï¼Œæ·»åŠ èƒŒæ™¯éŸ³è¾“å…¥
            if self.bgm_path:
                command.extend([
                    '-stream_loop', '-1',  # å¾ªç¯æ’­æ”¾èƒŒæ™¯éŸ³
                    '-i', self.bgm_path,
                    '-af', 'aresample=async=1000',  # åŠ éŸ³é¢‘é‡‡æ ·
                    '-c:a', 'aac',
                    '-ar', '44100',
                    '-b:a', '192k',
                    '-map', '0:v',  # æ˜ å°„è§†é¢‘æµ
                    '-map', '1:a',  # æ˜ å°„èƒŒæ™¯éŸ³ä¹
                ])
            
            # æ·»åŠ Bç«™ç›´æ’­ç‰¹å®šçš„ç¼–ç å‚æ•°
            command.extend([
                '-c:v', 'libx264',
                '-preset', 'superfast',
                '-tune', 'zerolatency',
                '-profile:v', 'baseline',
                '-pix_fmt', 'yuv420p',
                '-b:v', '2000k',
                '-maxrate', '2500k',
                '-bufsize', '2500k',
                '-r', '30',  # å›ºå®šè¾“å‡ºå¸§ç‡
                '-g', '30',  # å…³é”®å¸§é—´éš”ä¸å¸§ç‡ç›¸åŒ
                '-keyint_min', '30',  # æœ€å°å…³é”®å¸§é—´éš”ä¹Ÿè®¾ä¸ºå¸§ç‡
                '-sc_threshold', '0',
                '-thread_queue_size', '4096',
                '-max_muxing_queue_size', '2048',
                '-vsync', 'cfr',  # ä½¿ç”¨å›ºå®šå¸§ç‡æ¨¡å¼
                '-fps_mode', 'cfr',  # å¼ºåˆ¶å›ºå®šå¸§ç‡
                '-x264opts', 'no-scenecut:keyint=30:min-keyint=30',  # ç¡®ä¿å›ºå®šGOPå¤§å°
                '-probesize', '32',
                '-analyzeduration', '0',
            ])
            
            # æ·»åŠ å‡ºæ ¼å¼å’Œåœ°å€
            command.extend([
                '-f', 'flv',  # Bç«™ä½¿ç”¨FLVæ ¼å¼
                stream_url
            ])
            
            print("æ‰§è¡ŒFFmpegå‘½ä»¤:", ' '.join(command))
            
            # ä¿®æ”¹è¿›ç¨‹åˆ›å»º
            self.ffmpeg_process = subprocess.Popen(
                command,
                stdin=subprocess.PIPE,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                bufsize=10**8,
                creationflags=subprocess.CREATE_NO_WINDOW
            )

            # å»ºé”™è¯¯è¾“å‡ºç›‘æ§çº¿ç¨‹
            def monitor_ffmpeg():
                while self.ffmpeg_process and self.ffmpeg_process.poll() is None:
                    error_line = self.ffmpeg_process.stderr.readline()
                    if error_line:
                        error_text = error_line.decode().strip()
                        if "Error" in error_text or "error" in error_text:
                            print("FFmpegé”™è¯¯:", error_text)
                        elif "Warning" in error_text or "warning" in error_text:
                            print("FFmpegè­¦å‘Š:", error_text)
                        else:
                            print("FFmpeg:", error_text)  # æ‰“å°æ‰€æœ‰è¾“å‡ºä»¥ä¾¿è°ƒè¯•
                    time.sleep(0.1)

            self.ffmpeg_monitor = threading.Thread(target=monitor_ffmpeg)
            self.ffmpeg_monitor.daemon = True
            self.ffmpeg_monitor.start()

            print(f"æ¨æµå·²å¯åŠ¨åˆ°: {stream_url}")
            print(f"æ¨æµåˆ†è¾¨ç‡: {width}x{height}")
            
        except Exception as e:
            print(f"å¯åŠ¨æ¨æµæ—¶å‡ºé”™: {str(e)}")
            if hasattr(self, 'ffmpeg_process') and self.ffmpeg_process:
                self.ffmpeg_process.terminate()
                self.ffmpeg_process = None
    
    def stop_streaming(self):
        """åœæ­¢ç›´æ’­ä½†ä¸å½±å“å½•åˆ¶"""
        # åœæ­¢æ¨æµ
        if self.ffmpeg_process:
            self.ffmpeg_process.stdin.close()
            self.ffmpeg_process.terminate()
            self.ffmpeg_process.wait()
            self.ffmpeg_process = None
        
        self.streaming = False
        self.start_button.setText("å¼€å§‹ç›´æ’­")
        
        # å¦‚æœæ²¡æœ‰åœ¨å½•åˆ¶åˆ™åœæ­¢é¢„è§ˆå’Œé‡Šæ”¾èµ„æº
        if not self.recording:
            self.timer.stop()
            if hasattr(self, 'capture_region'):
                delattr(self, 'capture_region')
            if self.capture:
                self.capture.release()
            self.preview_label.clear()
            if not self.recording:
                self.stop_audio()
    
    def update_preview(self):
        """æ›´æ–°é¢„è§ˆã€æ¨æµå’Œå½•åˆ¶"""
        try:
            # ç²¾ç¡®çš„å¸§ç‡æ§åˆ¶
            current_time = time.time()
            if hasattr(self, '_last_update'):
                target_interval = 1.0 / 30  # ç›®æ ‡å¸§é—´éš”ï¼ˆ30fpsï¼‰
                elapsed = current_time - self._last_update
                if elapsed < target_interval:
                    return  # ç›´æ¥è¿”å›ï¼Œä¸ä½¿ç”¨sleep
            self._last_update = current_time

            frame_obtained = False
            try:
                if hasattr(self, 'capture_region'):
                    # ä½¿ç”¨numpyä¼˜åŒ–å›¾åƒå¤„ç†
                    with mss() as sct:
                        # ç›´æ¥è·å–BGRæ ¼å¼çš„å›¾åƒ
                        screenshot = np.array(sct.grab(self.capture_region))
                        
                        # å¦‚æœåˆ†è¾¨ç‡å¤ªå¤§ï¼Œå…ˆç¼©æ”¾å†å¤„ç†
                        if screenshot.shape[0] > 1080 or screenshot.shape[1] > 1920:
                            scale = min(1920/screenshot.shape[1], 1080/screenshot.shape[0])
                            new_size = (int(screenshot.shape[1] * scale), int(screenshot.shape[0] * scale))
                            screenshot = cv2.resize(screenshot, new_size, interpolation=cv2.INTER_AREA)
                        
                        # ç¡®ä¿å°ºå¯¸æ˜¯2çš„å€æ•°
                        h, w = screenshot.shape[:2]
                        w = w - (w % 2)
                        h = h - (h % 2)
                        if w != screenshot.shape[1] or h != screenshot.shape[0]:
                            screenshot = screenshot[:h, :w]
                        
                        # BGRè½¬æ¢
                        frame = cv2.cvtColor(screenshot, cv2.COLOR_BGRA2BGR)
                        record_frame = frame.copy()  # æ¨æµç”¨çš„ï¿½ï¿½
                        preview_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # é¢„è§ˆç”¨çš„å¸§
                        frame_obtained = True
                        self.frame_count += 1

                    # æ¨æµæ—¶ä½¿ç”¨è¾ƒå°çš„ç¼“å†²åŒº
                    if self.streaming and self.ffmpeg_process:
                        if self.ffmpeg_process.poll() is not None:
                            print("FFmpegè¿›ç¨‹å·²é€€å‡º")
                            error_output = self.ffmpeg_process.stderr.read().decode()
                            print("FFmpegé”™è¯¯è¾“å‡º:", error_output)
                            self.stop_streaming()
                            return
                        try:
                            # ç›´æ¥å†™å…¥æ•´ä¸ªå¸§æ•°æ®
                            self.ffmpeg_process.stdin.write(record_frame.tobytes())
                            self.ffmpeg_process.stdin.flush()
                        except Exception as e:
                            print(f"æ¨æµæ—¶å‡ºé”™: {str(e)}")
                            self.stop_streaming()
                            return

                    # æ›´æ–°é¢„è§ˆï¼ˆä½¿ç”¨QImageçš„å¿«é€Ÿè·¯å¾„ï¼‰
                    if frame_obtained:
                        h, w = preview_frame.shape[:2]
                        bytes_per_line = 3 * w
                        image = QImage(preview_frame.data, w, h, bytes_per_line, QImage.Format.Format_RGB888)
                        scaled_pixmap = QPixmap.fromImage(image).scaled(
                            self.preview_label.size(), 
                            Qt.AspectRatioMode.KeepAspectRatio,
                            Qt.TransformationMode.FastTransformation  # ä½¿ç”¨å¿«é€Ÿè½¬æ¢
                        )
                        self.preview_label.setPixmap(scaled_pixmap)

            except Exception as e:
                print(f"æ›´æ–°é¢„è§ˆæ—¶å‡ºé”™: {str(e)}")
                import traceback
                traceback.print_exc()

        except Exception as e:
            print(f"é¢„è§ˆæ›´æ–°ä¸»å¾ªç¯å‡ºé”™: {str(e)}")
    
    def get_audio_devices(self):
        """è·å–ç³»ç»ŸéŸ³é¢‘è®¾å¤‡åˆ—è¡¨"""
        try:
            devices = sd.query_devices()
            input_devices = ["é™éŸ³"]  # æ·»åŠ é™éŸ³é€‰é¡¹
            for i, device in enumerate(devices):
                if device['max_input_channels'] > 0:
                    input_devices.append(f"{i}: {device['name']}")
                    print(f"æ‰¾åˆ°éŸ³é¢‘è®¾å¤‡: {i}: {device['name']} (è¾“å…¥é€šé“: {device['max_input_channels']})")
            return input_devices
        except Exception as e:
            print(f"è·å–éŸ³é¢‘è®¾å¤‡åˆ—è¡¨å‡ºé”™: {str(e)}")
            return ["é™éŸ³"]
    
    def update_window_list(self):
        """æ›´æ–°å¯æ•è·çª—å£åˆ—è¡¨"""
        try:
            import win32gui
            def callback(hwnd, windows):
                if win32gui.IsWindowVisible(hwnd):
                    title = win32gui.GetWindowText(hwnd)
                    if title:
                        windows.append(title)
            windows = ["å…¨å±", "æ¡†é€‰åŒºåŸŸ"]  # ç¡®ä¿è¿™ä¸¤ä¸ªé€‰é¡¹å§‹ç»ˆå­˜åœ¨
            win32gui.EnumWindows(callback, windows)
            self.window_combo.clear()
            self.window_combo.addItems(windows)
        except ImportError:
            self.window_combo.addItems(["å…¨å±", "æ¡†é€‰åŒºåŸŸ", "éœ€è¦å®‰è£…pywin32åº“"])
    
    def refresh_devices(self):
        """åˆ·æ–°æ‰€æœ‰è®¾å¤‡åˆ—è¡¨"""
        # æ›´æ–°æ‘„åƒå¤´åˆ—è¡¨
        current_camera = self.camera_combo.currentText()
        self.update_camera_list()
        if current_camera in [self.camera_combo.itemText(i) for i in range(self.camera_combo.count())]:
            self.camera_combo.setCurrentText(current_camera)
            
        # æ›´æ–°éŸ³é¢‘è®¾å¤‡åˆ—è¡¨
        current_audio = self.audio_in_combo.currentText()
        self.audio_in_combo.clear()
        self.audio_in_combo.addItems(self.get_audio_devices())
        if current_audio in [self.audio_in_combo.itemText(i) for i in range(self.audio_in_combo.count())]:
            self.audio_in_combo.setCurrentText(current_audio)
            
        # æ›´æ–°çª—å£åˆ—è¡¨
        self.update_window_list()
    
    def audio_callback(self, indata, frames, time, status):
        """éŸ³é¢‘å›è°ƒå‡½æ•°"""
        if status:
            print(f"éŸ³é¢‘å›è°ƒçŠ¶æ€: {status}")
        if self.recording and self.is_recording_audio:
            try:
                # å°†æ•°æ®è½¬æ¢ä¸º16ä½æ•´æ•°å¹¶è°ƒæ•´éŸ³é‡
                audio_data = (indata * 32767 * 1.5).clip(-32768, 32767).astype(np.int16)
                self.audio_queue.put(audio_data)
            except Exception as e:
                print(f"éŸ³é¢‘å›è°ƒå¤„ç†å‡ºé”™: {str(e)}")
    
    def start_audio(self):
        """å¼€å§‹å½•åˆ¶ç³»ç»Ÿå£°éŸ³"""
        try:
            if self.audio_in_combo.currentText() == "é™éŸ³":
                print("å·²é€‰æ‹©é™éŸ³æ¨¡å¼")
                # è®¾ç½®é»˜è®¤çš„éŸ³é¢‘å‚æ•°
                self.audio_samplerate = 44100
                self.audio_channels = 2
                self.recording_audio = True
                self.is_recording_audio = True
                return
            
            # å°è¯•æŸ¥æ‰¾ç«‹ä½“å£°æ··éŸ³è®¾å¤‡
            devices = sd.query_devices()
            selected_device = None
            
            # ä»å½“å‰é€‰æ‹©çš„è®¾å¤‡æ–‡æœ¬ä¸­è·å–è®¾å¤‡ID
            device_text = self.audio_in_combo.currentText()
            if ':' in device_text:
                selected_device = int(device_text.split(':')[0])
            else:
                # æŸ¥æ‰¾ç«‹ä½“å£°æ··éŸ³è®¾å¤‡
                for i, device in enumerate(devices):
                    device_name = device['name'].lower()
                    if ('mix' in device_name or 
                        'stereo' in device_name or 
                        'ç«‹ä½“å£°æ··éŸ³' in device_name or 
                        'what u hear' in device_name or
                        'loopback' in device_name):
                        selected_device = i
                        break
            
            if selected_device is None:
                print("æœªæ‰¾åˆ°ç«‹ä½“å£°æ··éŸ³è®¾å¤‡ï¼Œè¯·åœ¨ç³»ç»Ÿå£°éŸ³è®¾ç½®ä¸­å¯ç”¨å®ƒ")
                print("Windowsç³»ç»Ÿå¯ç”¨æ–¹æ³•ï¼š")
                print("1. å³é”®ç‚¹å‡»ç³»ç»Ÿæ‰˜ç›˜éŸ³å›¾æ ‡")
                print('2. é€‰æ‹©"å£°éŸ³è®¾ç½®"')
                print('3. ç‚¹å‡»"å£°éŸ³æ§åˆ¶é¢æ¿"')
                print('4. åœ¨"å½•åˆ¶"æ ‡ç­¾é¡µ')
                print('5. å³é”®ç©ºç™½å¤„ï¼Œé€‰æ‹©"æ˜¾ç¤ºç¦ç”¨çš„è®¾å¤‡"')
                print('6. æ‰¾åˆ°"ç«‹ä½“å£°æ··éŸ³"ï¼Œå³é”®å¯ç”¨å®ƒ')
                return
            
            # è·å–è®¾å¤‡ä¿¡æ¯
            device_info = devices[selected_device]
            print(f"ä½¿ç”¨éŸ³é¢‘è®¾å¤‡: {device_info['name']}")
            
            # é…ç½®éŸ³é¢‘å‚æ•°
            self.audio_samplerate = int(device_info['default_samplerate'])
            self.audio_channels = min(2, device_info['max_input_channels'])
            
            # å¼€å½•åˆ¶
            self.recording_audio = True
            self.is_recording_audio = True
            
            # å¯åŠ¨å½•éŸ³æµ
            self.audio_stream = sd.InputStream(
                device=selected_device,
                channels=self.audio_channels,
                samplerate=self.audio_samplerate,
                callback=self.audio_callback,
                blocksize=1024,
                dtype=np.float32
            )
            self.audio_stream.start()
            
            print(f"ç³»ç»Ÿå£°éŸ³å½•åˆ¶å·²å¯åŠ¨: {self.audio_channels}é€šé“, {self.audio_samplerate}Hz")
            
        except Exception as e:
            print(f"éŸ³é¢‘å½•åˆ¶å‡ºé”™: {str(e)}")
            self.recording_audio = False
    
    def stop_audio(self):
        """åœæ­¢å½•åˆ¶éŸ³é¢‘"""
        self.recording_audio = False
        self.is_recording_audio = False
        if hasattr(self, 'audio_stream'):
            self.audio_stream.stop()
            self.audio_stream.close()
    
    def select_save_path(self):
        """é€‰æ‹©å½•åˆ¶æ–‡ä»¶ä¿å­˜è·¯å¾„"""
        folder = QFileDialog.getExistingDirectory(
            self,
            "é€‰æ‹©ä¿å­˜è·¯å¾„",
            self.save_path,
            QFileDialog.Option.ShowDirsOnly
        )
        if folder:
            self.save_path = folder
            self.save_path_label.setText(f"ä¿å­˜è·¯å¾„: {self.save_path}")
    
    def toggle_recording(self):
        """åˆ‡æ¢ï¿½ï¿½åˆ¶çŠ¶æ€"""
        if not self.recording:
            self.start_recording()
        else:
            self.stop_recording()
    
    def start_recording(self):
        """å¼€å§‹å½•åˆ¶"""
        try:
            if not self.streaming and not self.capture and not hasattr(self, 'capture_region'):
                selected_mode = self.window_combo.currentText()
                
                if selected_mode == "å…¨å±":
                    # è·å–ä¸»å±å¹•åˆ†è¾¨ç‡
                    screen = QApplication.primaryScreen()
                    size = screen.size()
                    self.capture_region = {
                        'left': 0,
                        'top': 0,
                        'width': size.width(),
                        'height': size.height()
                    }
                    self.timer.start(int(1000/30))  # ç²¾ç¡®çš„30fpså®šæ—¶å™¨é—´éš”
                
                elif selected_mode == "æ¡†é€‰åŒºåŸŸ":
                    if not self.select_area():
                        return
                    self.timer.start(int(1000/30))  # ç²¾ç¡®çš„30fpså®šæ—¶å™¨é—´éš”
                
                elif selected_mode != "éœ€è¦å®‰è£…pywin32åº“":
                    try:
                        import win32gui
                        window_title = selected_mode
                        hwnd = win32gui.FindWindow(None, window_title)
                        if hwnd:
                            # è·å–çª—å£ä½ç½®ï¼ŒåŒ…æ‹¬æœ€å°åŒ–çš„çª—å£
                            if win32gui.IsIconic(hwnd):  # å¦‚æœçª—å£æ˜¯æœ€å°åŒ–çš„
                                win32gui.ShowWindow(hwnd, 9)  # SW_RESTORE = 9
                            rect = win32gui.GetWindowRect(hwnd)
                            self.capture_region = {
                                'left': rect[0],
                                'top': rect[1],
                                'width': rect[2] - rect[0],
                                'height': rect[3] - rect[1]
                            }
                            self.target_window = hwnd  # ä¿å­˜ç›®æ ‡çª—å£å¥æŸ„
                            self.timer.start(int(1000/30))  # ç²¾ç¡®çš„30fpså®šæ—¶å™¨é—´éš”
                    except ImportError:
                        pass
                else:
                    self.capture = cv2.VideoCapture(self.camera_combo.currentIndex())
                    if not self.capture.isOpened():
                        raise Exception("æ— æ³•æ‰“å¼€æ‘„åƒå¤´")
                    self.timer.start(int(1000/30))  # ç²¾ç¡®çš„30fpså®šæ—¶å™¨é—´éš”
            
            # ç¡®ä¿éŸ³é¢‘è®¾å¤‡å·²ç»å¯åŠ¨
            if not self.recording_audio:
                self.start_audio()
            
            # ç¡®ä¿éŸ³é¢‘å‚æ•°å·²è®¾ç½®
            if not hasattr(self, 'audio_channels'):
                self.audio_channels = 2
            if not hasattr(self, 'audio_samplerate'):
                self.audio_samplerate = 44100
            
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            # ä¿å­˜æ–‡ä»¶è·¯å¾„ä½œä¸ºæˆå‘˜å˜é‡
            self.video_filename = os.path.join(self.save_path, f"recording_{timestamp}.mp4")
            self.audio_filename = os.path.join(self.save_path, f"recording_{timestamp}.wav")
            
            # è·å–è§†é¢‘å°ºå¯¸
            if hasattr(self, 'capture_region'):
                width = self.capture_region['width']
                height = self.capture_region['height']
            else:
                width = int(self.capture.get(cv2.CAP_PROP_FRAME_WIDTH))
                height = int(self.capture.get(cv2.CAP_PROP_FRAME_HEIGHT))
            
            # åˆ›å»ºè§†é¢‘å†™å…¥å™¨
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            self.video_writer = cv2.VideoWriter(
                self.video_filename,
                fourcc,
                30.0,
                (width, height)
            )
            
            if not self.video_writer.isOpened():
                raise Exception("æ— æ³•åˆ›å»ºè§†é¢‘æ–‡ä»¶")
            
            # åˆ›å»ºéŸ³é¢‘å†™å…¥å™¨
            self.audio_file = wave.open(self.audio_filename, 'wb')
            self.audio_file.setnchannels(self.audio_channels)  # ä½¿ç”¨è®¾å¤‡å®é™…é€šé“æ•°
            self.audio_file.setsampwidth(2)  # 16ä½é‡‡æ ·
            self.audio_file.setframerate(self.audio_samplerate)  # ä½¿ç”¨è®¾å¤‡çš„å®é™…é‡‡æ ·ç‡
            
            # å¼€å§‹å½•åˆ¶
            self.recording = True
            self.is_recording_audio = True
            self.recording_start_time = datetime.now()
            self.recording_timer.start(1000)  # æ¯ç§’æ›´æ–°ä¸€æ¬¡æ—¶é—´æ˜¾ç¤º
            
            # æ›´æ–°UI
            self.record_button.setText("åœæ­¢å½•åˆ¶")
            self.recording_status_label.setText("ğŸ”´ æ­£åœ¨å½•åˆ¶")
            
            # å¯åŠ¨éŸ³é¢‘å½•åˆ¶çº¿ç¨‹
            self.audio_thread = threading.Thread(target=self.record_audio)
            self.audio_thread.start()
            
            print(f"å¼€å§‹å½•åˆ¶åˆ°: {self.video_filename}")
            
            # å¦‚æœæœ‰èƒŒæ™¯éŸ³ä¹ï¼Œåˆ›å»ºæ··éŸ³å™¨
            if self.bgm_path:
                self.setup_audio_mixing()
            
        except Exception as e:
            print(f"å¼€å§‹å½•åˆ¶æ—¶å‡ºé”™: {str(e)}")
            self.stop_recording()
    
    def record_audio(self):
        """éŸ³é¢‘å½•åˆ¶çº¿ç¨‹"""
        while self.is_recording_audio and self.audio_file:
            try:
                if not self.audio_queue.empty():
                    audio_data = self.audio_queue.get()
                    if audio_data is not None and len(audio_data) > 0:
                        self.audio_file.writeframes(audio_data.tobytes())
            except Exception as e:
                print(f"éŸ³é¢‘å½•åˆ¶å‡ºé”™: {str(e)}")
                break
            time.sleep(0.001)
    
    def stop_recording(self):
        """åœæ­¢å½•åˆ¶ä½†ä¸å½±å“ç›´æ’­"""
        try:
            # åœæ­¢è§†é¢‘å½•åˆ¶
            if self.video_writer:
                self.video_writer.release()
                self.video_writer = None
            
            # åœæ­¢éŸ³é¢‘å½•åˆ¶
            self.is_recording_audio = False
            if self.audio_thread:
                self.audio_thread.join()
            if self.audio_file:
                self.audio_file.close()
                self.audio_file = None
            
            # åˆå¹¶éŸ³è§†é¢‘
            if hasattr(self, 'video_filename') and hasattr(self, 'audio_filename'):
                try:
                    output_path = os.path.splitext(self.video_filename)[0] + '_merged.mp4'
                    
                    # ä½¿ç”¨ffmpegåˆå¹¶éŸ³è§†é¢‘
                    stream = ffmpeg.input(self.video_filename)
                    audio = ffmpeg.input(self.audio_filename)
                    stream = ffmpeg.output(stream, audio, output_path, vcodec='copy', acodec='aac')
                    ffmpeg.run(stream, overwrite_output=True)
                    
                    # åˆ é™¤åŸå§‹æ–‡ä»¶
                    os.remove(self.video_filename)
                    os.remove(self.audio_filename)
                    
                    # æ¸…ç†æ–‡ä»¶è·¯å¾„
                    delattr(self, 'video_filename')
                    delattr(self, 'audio_filename')
                    
                    print(f"éŸ³è§†é¢‘åˆå¹¶å®Œæˆ: {output_path}")
                    
                except Exception as e:
                    print(f"åˆå¹¶éŸ³è§†é¢‘æ—¶å‡ºé”™: {str(e)}")
            
            # åœæ­¢å®šæ—¶å™¨
            self.recording_timer.stop()
            
            # é‡ç½®çŠ¶æ€
            self.recording = False
            self.recording_start_time = None
            
            # æ›´æ–°UI
            self.record_button.setText("å¼€å§‹å½•åˆ¶")
            self.recording_status_label.setText("âšª æœªå½•åˆ¶")
            self.recording_time_label.setText("å½•åˆ¶æ—¶é•¿: 00:00:00")
            
            # æœæ²¡æœ‰åœ¨ç›´æ’­ï¼Œåˆ™åœæ­¢é¢„è§ˆå’Œé‡Šæ”¾èµ„æº
            if not self.streaming:
                self.timer.stop()
                if hasattr(self, 'capture_region'):
                    delattr(self, 'capture_region')
                if self.capture:
                    self.capture.release()
                self.preview_label.clear()
                self.stop_audio()
                
        except Exception as e:
            print(f"åœæ­¢å½•åˆ¶æ—¶å‡ºé”™: {str(e)}")
        finally:
            # é‡ç½®çŠ¶æ€
            self.recording = False
            self.recording_start_time = None
            self.recording_timer.stop()
            
            # æ›´æ–°UI
            self.record_button.setText("å¼€å§‹å½•åˆ¶")
            self.recording_status_label.setText("âšª æœªå½•åˆ¶")
            self.recording_time_label.setText("å½•åˆ¶æ—¶é•¿: 00:00:00")
    
    def update_recording_time(self):
        """æ›´æ–°å½•åˆ¶æ—¶é•¿æ˜¾ç¤º"""
        if self.recording and self.recording_start_time:
            elapsed = datetime.now() - self.recording_start_time
            hours = elapsed.seconds // 3600
            minutes = (elapsed.seconds % 3600) // 60
            seconds = elapsed.seconds % 60
            self.recording_time_label.setText(
                f"å½•åˆ¶æ—¶é•¿: {hours:02d}:{minutes:02d}:{seconds:02d}"
            )
    
    def closeEvent(self, event):
        """çª—å£å…³é—­äº‹ä»¶å¤„ç†"""
        if self.recording or self.streaming:
            reply = QMessageBox.question(
                self, 
                'ç¡®è®¤é€€å‡º', 
                "å½•åˆ¶æˆ–ç›´æ’­æ­£åœ¨è¿›è¡Œä¸­ï¼Œæ˜¯å¦æœ€å°åŒ–åˆ°ç³»ç»Ÿæ‰˜ç›˜ç»§ç»­è¿è¡Œï¼Ÿ",
                QMessageBox.StandardButton.Yes | 
                QMessageBox.StandardButton.No | 
                QMessageBox.StandardButton.Cancel
            )
            
            if reply == QMessageBox.StandardButton.Yes:
                event.ignore()
                self.hide()
                self.create_tray_icon()
            elif reply == QMessageBox.StandardButton.No:
                self.cleanup_resources()
                event.accept()
            else:
                event.ignore()
        else:
            self.cleanup_resources()
            event.accept()
    
    def changeEvent(self, event):
        """çª—å£çŠ¶æ€æ”¹å˜äº‹ä»¶å¤„ç†"""
        if event.type() == QEvent.Type.WindowStateChange:
            if self.windowState() & Qt.WindowState.WindowMinimized:
                if self.recording or self.streaming:
                    # æœ€å°åŒ–æ—¶è‡ªåŠ¨éšè—åˆ°ç³»ç»Ÿæ‰˜ç›˜
                    self.hide()
                    if not self.tray_icon:
                        self.create_tray_icon()
                    if self.tray_icon and not hasattr(self, 'minimize_notice_shown'):
                        self.tray_icon.showMessage(
                            "ç¨‹åºå·²æœ€å°åŒ–",
                            "ç¨‹åºå°†åœ¨åå°ç»§ç»­è¿è¡Œï¼ŒåŒå‡»æ‰˜ç›˜å›¾æ ‡å¯ä»¥æ¢å¤çª—å£",
                            QSystemTrayIcon.MessageIcon.Information,
                            2000
                        )
                        self.minimize_notice_shown = True
    
    def create_tray_icon(self):
        """åˆ›å»ºç³»ç»Ÿæ‰˜ç›˜å›¾æ ‡"""
        if not self.tray_icon:
            from PyQt6.QtWidgets import QStyle
            self.tray_icon = QSystemTrayIcon(self)
            self.tray_icon.setIcon(self.style().standardIcon(QStyle.StandardPixmap.SP_ComputerIcon))
            
            # åˆ›å»ºæ‰˜ç›˜èœå•
            tray_menu = QMenu()
            
            # æ˜¾ç¤ºä¸»çª—å£åŠ¨ä½œ
            show_action = tray_menu.addAction("æ˜¾ç¤ºä¸»çª—å£")
            show_action.triggered.connect(self.show)
            
            # åœæ­¢å½•åˆ¶åŠ¨ä½œ
            stop_record_action = tray_menu.addAction("åœæ­¢å½•åˆ¶")
            stop_record_action.triggered.connect(self.stop_recording)
            
            # é€€å‡ºåŠ¨ä½œ
            quit_action = tray_menu.addAction("é€€å‡º")
            quit_action.triggered.connect(self.force_quit)
            
            self.tray_icon.setContextMenu(tray_menu)
            self.tray_icon.show()
            
            # æ·»åŠ æ‰˜ç›˜å›¾æ ‡åŒå‡»äº‹ä»¶
            self.tray_icon.activated.connect(self.tray_icon_activated)
    
    def tray_icon_activated(self, reason):
        """æ‰˜ç›˜å›¾æ ‡æ¿€æ´»äº‹ä»¶å¤„ç†"""
        if reason == QSystemTrayIcon.ActivationReason.DoubleClick:
            self.show()
    
    def force_quit(self):
        """å¼ºåˆ¶é€€å‡ºç¨‹åº"""
        if self.recording:
            self.stop_recording()
        QApplication.quit()
    
    def select_bgm(self):
        """é€‰æ‹©èƒŒæ™¯éŸ³ä¹"""
        file_name, _ = QFileDialog.getOpenFileName(
            self,
            "é€‰æ‹©èƒŒæ™¯éŸ³ä¹",
            "",
            "éŸ³é¢‘æ–‡ä»¶ (*.mp3 *.wav *.m4a)"
        )
        if file_name:
            self.bgm_path = file_name
            self.bgm_label.setText(os.path.basename(file_name))
    
    def select_area(self):
        """é€‰æ‹©åˆ¶åŒºåŸŸ"""
        dialog = SelectAreaDialog()
        if dialog.exec() == QDialog.DialogCode.Accepted:
            rect = dialog.selected_rect
            if rect:
                self.capture_region = {
                    'left': rect.x(),
                    'top': rect.y(),
                    'width': rect.width(),
                    'height': rect.height()
                }
                return True
        return False
    
    def setup_audio_mixing(self):
        """è®¾ç½®éŸ³é¢‘æ··éŸ³"""
        try:
            # è¯»å–éŸ³é¢‘æ–‡ä»¶ï¼ˆæ”¯æŒMP3å’ŒWAVï¼‰
            audio = AudioSegment.from_file(self.bgm_path)
            
            # è°ƒæ•´éŸ³é‡ï¼ˆå¯ä»¥æ ¹æ®éœ€è¦è°ƒæ•´ï¼‰
            audio = audio + 10  # å¢åŠ 10dB
            
            # è½¬æ¢ä¸ºWAVæ ¼å¼
            wav_data = io.BytesIO()
            audio.export(wav_data, format='wav')
            wav_data.seek(0)
            
            # æ‰“å¼€éŸ³é¢‘æ–‡ä»¶
            self.bgm_data = wave.open(wav_data, 'rb')
            self.bgm_position = 0
            
            # è°ƒæ•´æ ·ç‡å’Œé€šé“æ•°ä»¥åŒ¹é…å½•åˆ¶è®¾ç½®
            if hasattr(self, 'audio_samplerate'):
                target_samplerate = self.audio_samplerate
            else:
                target_samplerate = 44100
            
            if self.bgm_data.getframerate() != target_samplerate:
                print(f"è­¦å‘Šï¼šèƒŒæ™¯éŸ³ä¹é‡‡æ ·ç‡({self.bgm_data.getframerate()})ä¸å½•åˆ¶é‡‡æ ·ç‡({target_samplerate})ä¸åŒ¹é…")
            
            print("èƒŒæ™¯éŸ³ä¹å·²åŠ è½½")
            
            # å¯åŠ¨èƒŒæ™¯éŸ³ä¹å¤„ç†çº¿ç¨‹
            self.bgm_thread = threading.Thread(target=self.process_bgm)
            self.bgm_thread.daemon = True
            self.bgm_thread.start()
            
        except Exception as e:
            print(f"è®¾ç½®èƒŒæ™¯éŸ³ä¹å‡ºé”™: {str(e)}")
            self.bgm_path = None
            self.bgm_label.setText("åŠ è½½å¤±è´¥")
    
    def process_bgm(self):
        """å¤„ç†èƒŒæ™¯éŸ³ä¹"""
        try:
            while self.recording and hasattr(self, 'bgm_data'):
                # è¯»å–èƒŒæ™¯éŸ³ä¹æ•°æ®
                frames = 1024  # è°ƒæ•´ç¼“å†²åŒºå¤§å°
                bgm_frames = self.bgm_data.readframes(frames)
                
                if not bgm_frames:
                    # å¾ªç¯æ’­æ”¾
                    self.bgm_data.rewind()
                    bgm_frames = self.bgm_data.readframes(frames)
                
                # å°†å­—èŠ‚æ•°æ®è½¬æ¢ä¸ºnumpyç»„
                bgm_data = np.frombuffer(bgm_frames, dtype=np.int16)
                
                # ç¡®ä¿éŸ³é¢‘é€šé“æ•°åŒ¹é…
                if bgm_data.size > 0:  # ç¡®ä¿æœ‰æ•°æ®
                    if self.bgm_data.getnchannels() == 1:  # å•å£°é“è½¬ç«‹ä½“å£°
                        bgm_data = np.repeat(bgm_data, 2)
                    bgm_data = bgm_data.reshape(-1, 2)  # åˆ¶ä½¿ç”¨2é€šé“
                
                # å¦‚æœæ˜¯é™éŸ³æ¨¡å¼ï¼Œç›´æ¥ä½¿ç”¨èƒŒæ™¯éŸ³ä¹
                if self.audio_in_combo.currentText() == "é™éŸ³":
                    self.audio_queue.put(bgm_data)
                else:
                    # ç­‰å¾…ç³»ç»ŸéŸ³é¢‘æ•°
                    if not self.audio_queue.empty():
                        system_audio = self.audio_queue.get()
                        # ç¡®ä¿ä¸¤ä¸ªéŸ³é¢‘çš„å½¢çŠ¶åŒ¹é…
                        if system_audio.shape[0] != bgm_data.shape[0]:
                            # è°ƒæ•´èƒŒæ™¯éŸ³ä¹é•¿åº¦ä»¥åŒ¹é…ç³»ç»ŸéŸ³é¢‘
                            if system_audio.shape[0] > bgm_data.shape[0]:
                                bgm_data = np.pad(bgm_data, ((0, system_audio.shape[0] - bgm_data.shape[0]), (0, 0)))
                            else:
                                bgm_data = bgm_data[:system_audio.shape[0]]
                        # åˆéŸ³é¢‘ï¼ˆè°ƒæ•´æ··åˆæ¯”ä¾‹ï¼‰
                        mixed_data = (system_audio * 0.7 + bgm_data * 0.3).clip(-32768, 32767).astype(np.int16)
                        self.audio_queue.put(mixed_data)
                
                time.sleep(0.001)
                
        except Exception as e:
            print(f"èƒŒæ™¯éŸ³ä¹å¤„ç†å‡ºé”™: {str(e)}")
            print(f"é”™è¯¯è¯¦æƒ…: {str(e.__traceback__)}")
    
    def update_camera_list(self):
        """æ›´æ–°æ‘„åƒå¤´åˆ—è¡¨"""
        available_cameras = []
        # æ£€æŸ¥å¯ç”¨çš„æ‘„åƒå¤´
        for i in range(10):  # æ£€æŸ¥å‰10ä¸ªç´¢å¼•
            cap = cv2.VideoCapture(i)
            if cap.isOpened():
                # è¯»å–ä¸€å¸§æµ‹è¯•æ˜¯å¦å¯ç”¨
                ret, _ = cap.read()
                if ret:
                    available_cameras.append(f"æ‘„åƒå¤´ {i}")
                cap.release()
        
        if not available_cameras:
            available_cameras = ["æ— å¯ç”¨æ‘„åƒå¤´"]
        
        self.camera_combo.clear()
        self.camera_combo.addItems(available_cameras)

    def cleanup_resources(self):
        """æ¸…ç†æ‰€æœ‰èµ„æº"""
        try:
            # åœæ­¢å®šæ—¶å™¨
            self.timer.stop()
            
            # åœæ­¢æ¨æµ
            if hasattr(self, 'ffmpeg_process') and self.ffmpeg_process:
                self.ffmpeg_process.terminate()
                self.ffmpeg_process.wait()
                self.ffmpeg_process = None
            
            # åœæ­¢å½•åˆ¶
            if self.recording:
                self.stop_recording()
            
            # é‡Šæ”¾æ‘„åƒå¤´
            if self.capture:
                self.capture.release()
            
            # åœæ­¢éŸ³é¢‘
            self.stop_audio()
            
        except Exception as e:
            print(f"æ¸…ç†èµ„æºæ—¶å‡ºé”™: {str(e)}")

    def monitor_performance(self):
        """ç›‘æ§æ¨æµæ€§èƒ½"""
        try:
            current_time = time.time()
            elapsed = current_time - self.last_frame_time
            fps = self.frame_count / elapsed if elapsed > 0 else 0
            
            if self.streaming:
                print(f"å½“å‰å¸§ç‡: {fps:.1f} FPS")
                if abs(fps - 30) > 2:  # å¦‚æœå¸§ç‡åç¦»30fpsè¶…è¿‡2å¸§
                    print(f"è­¦å‘Š: å¸§ç‡ä¸ç¨³å®š ({fps:.1f} FPS)")
                    # æä¾›ä¼˜åŒ–å»ºè®®
                    if fps < 25:
                        print("æ€§èƒ½ä¼˜åŒ–å»ºè®®:")
                        print("1. é™ä½æ•è·åŒºåŸŸåˆ†è¾¨ç‡")
                        print("2. å…³é—­ä¸å¿…è¦çš„åå°ç¨‹åº")
                        print("3. æ£€æŸ¥CPUä½¿ç”¨ç‡å’Œæ¸©åº¦")
                
                # æ£€æŸ¥ç³»ç»Ÿèµ„æº
                if hasattr(self, 'ffmpeg_process'):
                    process = psutil.Process(self.ffmpeg_process.pid)
                    cpu_percent = process.cpu_percent()
                    memory_percent = process.memory_percent()
                    
                    # è·å–ç³»ç»Ÿæ€»ä½“CPUä½¿ç”¨ç‡
                    system_cpu = psutil.cpu_percent()
                    print(f"ç³»ç»ŸCPUä½¿ç”¨ç‡: {system_cpu:.1f}%")
                    print(f"FFmpeg CPUä½¿ç”¨ç‡: {cpu_percent:.1f}%, å†…å­˜ä½¿ç”¨ç‡: {memory_percent:.1f}%")
                    
                    # æ£€æŸ¥CPUæ˜¯å¦è¿‡è½½
                    if system_cpu > 80:
                        print("è­¦å‘Š: ç³»ç»ŸCPUä½¿ç”¨ç‡è¿‡é«˜")
                    
                    # æ£€æŸ¥å¸§ç‡ç¨³å®šæ€§
                    if hasattr(self, '_frame_times'):
                        frame_times = getattr(self, '_frame_times')
                        if len(frame_times) > 30:
                            frame_times.pop(0)
                        frame_times.append(current_time)
                        
                        if len(frame_times) > 1:
                            intervals = np.diff(frame_times)
                            jitter = np.std(intervals) * 1000
                            print(f"å¸§é—´éš”æŠ–åŠ¨: {jitter:.2f}ms")
                            
                            if jitter > 20:
                                print("è­¦å‘Š: å¸§ç‡ä¸ç¨³å®šï¼Œå»ºè®®æ£€æŸ¥ç³»ç»Ÿæ€§èƒ½")
                    else:
                        self._frame_times = []
            
            self.frame_count = 0
            self.last_frame_time = current_time
            
        except Exception as e:
            print(f"æ€§èƒ½ç›‘æ§å‡ºé”™: {str(e)}")

    def merge_audio_video(self, video_file, audio_file, output_file):
        """åˆå¹¶éŸ³é¢‘å’Œè§†é¢‘æ–‡ä»¶"""
        try:
            # ä½¿ç”¨æ­£ç¡®çš„æµæ˜ å°„
            command = [
                'ffmpeg',
                '-i', video_file,  # è§†é¢‘è¾“å…¥
                '-i', audio_file,  # éŸ³é¢‘è¾“å…¥
                '-c:v', 'copy',    # å¤åˆ¶è§†é¢‘æµ
                '-c:a', 'aac',     # å°†éŸ³é¢‘è½¬æ¢ä¸º AAC æ ¼å¼
                '-map', '0:v:0',   # ä»ç¬¬ä¸€ä¸ªè¾“å…¥å–è§†é¢‘æµ
                '-map', '1:a:0',   # ä»ç¬¬äºŒä¸ªè¾“å…¥å–éŸ³é¢‘æµ
                '-shortest',       # ä½¿ç”¨æœ€çŸ­çš„æµé•¿åº¦
                output_file
            ]
            
            # æ‰§è¡Œå‘½ä»¤
            result = subprocess.run(
                command,
                capture_output=True,
                text=True
            )
            
            if result.returncode != 0:
                print("FFmpegé”™è¯¯è¾“å‡º:", result.stderr)
                raise Exception("FFmpegå‘½ä»¤æ‰§è¡Œå¤±è´¥")
            
            print("éŸ³è§†é¢‘åˆå¹¶å®Œæˆ")
            
        except Exception as e:
            print(f"åˆå¹¶éŸ³è§†é¢‘æ—¶å‡ºé”™: {str(e)}")
            if os.path.exists(output_file):
                try:
                    os.remove(output_file)
                except:
                    pass
            raise

# åœ¨ç¨‹åºå¼€å§‹æ—¶æ·»åŠ èµ„æºè·¯å¾„æ£€æŸ¥
def check_ffmpeg():
    """æ£€æŸ¥FFmpegæ˜¯å¦å¯ç”¨"""
    try:
        ffmpeg_path = os.path.join(os.path.dirname(sys.executable), 'ffmpeg.exe')
        if not os.path.exists(ffmpeg_path):
            ffmpeg_path = 'ffmpeg'  # å°è¯•ä½¿ç”¨ç³»ç»ŸPATHä¸­çš„ffmpeg
        
        result = subprocess.run([ffmpeg_path, '-version'], 
                              capture_output=True, 
                              text=True)
        if result.returncode == 0:
            return True
        return False
    except Exception:
        return False

if __name__ == '__main__':
    app = QApplication(sys.argv)
    
    # æ£€æŸ¥FFmpeg
    if not check_ffmpeg():
        QMessageBox.critical(None, 
                           "é”™è¯¯", 
                           "æœªæ‰¾åˆ°FFmpegï¼Œè¯·ç¡®ä¿ffmpeg.exeåœ¨ç¨‹åºç›®å½•ä¸‹æˆ–å·²æ·»åŠ åˆ°ç³»ç»ŸPATHä¸­")
        sys.exit(1)
    
    window = StreamingApp()
    window.show()
    sys.exit(app.exec()) 